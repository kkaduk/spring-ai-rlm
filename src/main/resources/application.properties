spring.application.name=spring-ai-rlm

spring.cache.type=caffeine
spring.cache.caffeine.spec=maximumSize=100,expireAfterWrite=3600s

server.port=8080

# RLM Configuration
rlm.max-depth=3
rlm.max-branching=3
rlm.timeout-seconds=30
rlm.enable-caching=true
rlm.decomposition-temperature=0.8
rlm.solving-temperature=0.7
rlm.aggregation-temperature=0.6

logging.level.com.example.rlm=DEBUG
logging.level.org.springframework.ai=INFO
logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss} - %msg%n


spring.ai.chat.client.enabled=false
# spring.ai.model.chat=google-genai
# spring.ai.model.chat=anthropic
# spring.ai.model.chat=openai
# spring.ai.model.chat=none

# --- Google Gemini Configuration ---
spring.ai.google.genai.api-key=${GEMINI_API_KEY:your-api-key-here}
# spring.ai.google.genai.chat.options.model=gemini-3-pro-preview
# spring.ai.google.genai.chat.options.model=gemma-3-27b-it
spring.ai.google.genai.chat.options.model=gemini-2.5-flash
spring.ai.google.genai.enabled=false
# spring.ai.google.genai.chat.options.temperature=0.1
spring.ai.google.genai.chat.options.response-mime-type=text/plain
# spring.ai.google.genai.chat.options.top-k=40
# spring.ai.google.genai.chat.options.top-p=0.95
# spring.ai.google.genai.chat.options.candidate-count=1
# spring.ai.google.genai.chat.options.thinking-budget
spring.ai.google.genai.chat.enable-cached-content=false

# Disable audio/speech and transcription auto-configs to avoid requiring OpenAI keys in tests
spring.ai.model.audio.speech=none
spring.ai.model.audio.transcription=none
# Disable other model types to prevent OpenAI auto-config from requiring keys in tests
spring.ai.model.embedding=none
spring.ai.model.image=none
spring.ai.model.rerank=none

#Antropic
spring.ai.anthropic.chat.options.model=claude-3-haiku-20240307
#spring.ai.anthropic.chat.options.model=claude-opus-4-5
# spring.ai.anthropic.chat.options.temperature=0.1
spring.ai.anthropic.api-key=${ANTHROPIC_API_KEY:your-api-key-here}
spring.ai.anthropic.enabled=true
# spring.ai.anthropic.genai.chat.options.top-p=0.9
spring.ai.anthropic.chat.options.max-tokens=40000



#OpenaAI
# spring.ai.openai.chat.options.model=gpt-5.2
# spring.ai.openai.chat.options.model=gpt-4
spring.ai.openai.chat.options.model=gpt-4.1-nano-2025-04-14
spring.ai.openai.chat.options.temperature=1
spring.ai.openai.api-key=${OPENAI_API_KEY:your-api-key-here}
spring.ai.openai.enabled=false
# spring.ai.openai.genai.chat.options.top-p=0.9
# spring.ai.openai.chat.options.responseFormat=text
# spring.ai.openai.chat.options.temperature=0.1


# application.properties

# === RLM Core Settings ===
rlm.max-depth=5
rlm.max-branching=3
rlm.timeout-seconds=300
rlm.enable-caching=false
rlm.execution-timeout-seconds=30

# === Security Settings ===
rlm.security.allow-network=false
rlm.security.allow-file-system=true
rlm.security.max-file-size-mb=10

# List properties use indexed notation in .properties
rlm.security.allowed-commands[0]=python3
rlm.security.allowed-commands[1]=bash
